"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[113],{7133(e,n,r){r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>m,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-1-ros2/ai-ros-integration","title":"Connecting AI Agents to ROS Controllers","description":"Using Python and rclpy to connect AI algorithms to ROS 2 systems","source":"@site/docs/module-1-ros2/ai-ros-integration.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/ai-ros-integration","permalink":"/my-book/docs/module-1-ros2/ai-ros-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/bydjusman/my-book/edit/main/docs/module-1-ros2/ai-ros-integration.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Connecting AI Agents to ROS Controllers","description":"Using Python and rclpy to connect AI algorithms to ROS 2 systems"},"sidebar":"tutorialSidebar","previous":{"title":"Nodes, Topics, and Services","permalink":"/my-book/docs/module-1-ros2/nodes-topics-services"},"next":{"title":"URDF and Humanoid Robot Structure","permalink":"/my-book/docs/module-1-ros2/urdf-structure"}}');var o=r(4848),i=r(8453);const t={sidebar_position:6,title:"Connecting AI Agents to ROS Controllers",description:"Using Python and rclpy to connect AI algorithms to ROS 2 systems"},l="Connecting Python AI Agents to ROS Controllers using rclpy",a={},c=[{value:"Introduction to rclpy",id:"introduction-to-rclpy",level:2},{value:"Setting Up rclpy",id:"setting-up-rclpy",level:2},{value:"Creating Publishers and Subscribers",id:"creating-publishers-and-subscribers",level:2},{value:"Subscribers for Sensor Data",id:"subscribers-for-sensor-data",level:3},{value:"Publishers for Control Commands",id:"publishers-for-control-commands",level:3},{value:"Quality of Service (QoS) Configuration",id:"quality-of-service-qos-configuration",level:3},{value:"Integrating AI Models with ROS 2",id:"integrating-ai-models-with-ros-2",level:2},{value:"Loading AI Models",id:"loading-ai-models",level:3},{value:"Real-time Performance Considerations",id:"real-time-performance-considerations",level:3},{value:"Services for Synchronous Operations",id:"services-for-synchronous-operations",level:2},{value:"Actions for Long-Running Tasks",id:"actions-for-long-running-tasks",level:2},{value:"Example: Complete AI-ROS Integration",id:"example-complete-ai-ros-integration",level:2},{value:"Best Practices for AI-ROS Integration",id:"best-practices-for-ai-ros-integration",level:2},{value:"Design Patterns",id:"design-patterns",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"connecting-python-ai-agents-to-ros-controllers-using-rclpy",children:"Connecting Python AI Agents to ROS Controllers using rclpy"})}),"\n",(0,o.jsx)(n.h2,{id:"introduction-to-rclpy",children:"Introduction to rclpy"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"rclpy"})," is the Python client library for ROS 2, providing Python bindings for the ROS 2 client library (rcl). It enables Python-based AI agents to integrate with ROS 2-based robotic systems, creating a bridge between AI algorithms and robotic hardware control."]}),"\n",(0,o.jsxs)(n.p,{children:["Python has become the dominant language for AI development due to its rich ecosystem of libraries like TensorFlow, PyTorch, and scikit-learn. ",(0,o.jsx)(n.code,{children:"rclpy"})," leverages these advantages while maintaining compatibility with the broader ROS 2 ecosystem, making it ideal for integrating AI algorithms with robotic systems."]}),"\n",(0,o.jsx)(n.h2,{id:"setting-up-rclpy",children:"Setting Up rclpy"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"rclpy"})," is typically installed as part of a ROS 2 distribution. For most users, it's available after installing ROS 2 and sourcing the setup script:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"source /opt/ros/humble/setup.bash  # or your ROS 2 distribution\n"})}),"\n",(0,o.jsxs)(n.p,{children:["A typical ",(0,o.jsx)(n.code,{children:"rclpy"})," node follows this structure:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\n\r\nclass AIControllerNode(Node):\r\n    def __init__(self):\r\n        super().__init__('ai_controller_node')\r\n        # Initialize publishers, subscribers, services, etc.\r\n        # Set up AI model if needed\r\n        # Configure parameters\r\n\r\ndef main():\r\n    rclpy.init()\r\n    node = AIControllerNode()\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\n"})}),"\n",(0,o.jsx)(n.h2,{id:"creating-publishers-and-subscribers",children:"Creating Publishers and Subscribers"}),"\n",(0,o.jsx)(n.h3,{id:"subscribers-for-sensor-data",children:"Subscribers for Sensor Data"}),"\n",(0,o.jsx)(n.p,{children:"AI agents need to receive sensor data to perceive the environment:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from sensor_msgs.msg import Image, LaserScan, Imu, JointState\r\nfrom std_msgs.msg import String\r\n\r\nclass PerceptionNode(Node):\r\n    def __init__(self):\r\n        super().__init__('perception_node')\r\n\r\n        # Subscribe to camera data\r\n        self.image_subscription = self.create_subscription(\r\n            Image,\r\n            '/camera/image_raw',\r\n            self.image_callback,\r\n            10)  # QoS history depth\r\n\r\n        # Subscribe to joint states\r\n        self.joint_subscription = self.create_subscription(\r\n            JointState,\r\n            '/joint_states',\r\n            self.joint_callback,\r\n            10)\r\n\r\n        # Store the latest sensor data\r\n        self.latest_image = None\r\n        self.latest_joints = None\r\n\r\n    def image_callback(self, msg):\r\n        self.latest_image = msg\r\n        # Process image data with AI algorithm\r\n\r\n    def joint_callback(self, msg):\r\n        self.latest_joints = msg\r\n        # Process joint state data\n"})}),"\n",(0,o.jsx)(n.h3,{id:"publishers-for-control-commands",children:"Publishers for Control Commands"}),"\n",(0,o.jsx)(n.p,{children:"AI agents publish commands to control the robot:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from geometry_msgs.msg import Twist\r\nfrom sensor_msgs.msg import JointState\r\n\r\nclass AIControllerNode(Node):\r\n    def __init__(self):\r\n        super().__init__('ai_controller')\r\n\r\n        # Publisher for robot velocity commands\r\n        self.cmd_vel_publisher = self.create_publisher(\r\n            Twist,\r\n            '/cmd_vel',\r\n            10)\r\n\r\n        # Publisher for joint position commands\r\n        self.joint_cmd_publisher = self.create_publisher(\r\n            JointState,\r\n            '/joint_group_position_controller/commands',\r\n            10)\r\n\r\n    def send_velocity_command(self, linear_x, linear_y, angular_z):\r\n        msg = Twist()\r\n        msg.linear.x = linear_x\r\n        msg.linear.y = linear_y\r\n        msg.angular.z = angular_z\r\n        self.cmd_vel_publisher.publish(msg)\r\n\r\n    def send_joint_positions(self, joint_names, positions):\r\n        msg = JointState()\r\n        msg.name = joint_names\r\n        msg.position = positions\r\n        self.joint_cmd_publisher.publish(msg)\n"})}),"\n",(0,o.jsx)(n.h3,{id:"quality-of-service-qos-configuration",children:"Quality of Service (QoS) Configuration"}),"\n",(0,o.jsx)(n.p,{children:"Configure QoS settings to match your application's requirements:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from rclpy.qos import QoSProfile, ReliabilityPolicy\r\n\r\n# For critical control commands - reliable delivery\r\ncontrol_qos = QoSProfile(\r\n    depth=10,\r\n    reliability=ReliabilityPolicy.RELIABLE,\r\n    history=HistoryPolicy.KEEP_LAST\r\n)\r\n\r\n# Create publisher with custom QoS\r\nself.control_publisher = self.create_publisher(\r\n    Twist,\r\n    '/cmd_vel',\r\n    qos_profile=control_qos\r\n)\n"})}),"\n",(0,o.jsx)(n.h2,{id:"integrating-ai-models-with-ros-2",children:"Integrating AI Models with ROS 2"}),"\n",(0,o.jsx)(n.h3,{id:"loading-ai-models",children:"Loading AI Models"}),"\n",(0,o.jsx)(n.p,{children:"AI models can be loaded within ROS 2 nodes for real-time inference:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import tensorflow as tf\r\nimport torch\r\nfrom sensor_msgs.msg import Image\r\nfrom cv_bridge import CvBridge\r\n\r\nclass AIInferenceNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'ai_inference_node\')\r\n\r\n        # Initialize OpenCV bridge for image conversion\r\n        self.bridge = CvBridge()\r\n\r\n        # Load pre-trained models\r\n        self.load_models()\r\n\r\n        # Subscribe to sensor data\r\n        self.image_subscription = self.create_subscription(\r\n            Image,\r\n            \'/camera/image_raw\',\r\n            self.inference_callback,\r\n            10)\r\n\r\n        # Publisher for inference results\r\n        self.result_publisher = self.create_publisher(\r\n            String,\r\n            \'/ai/inference_result\',\r\n            10)\r\n\r\n    def load_models(self):\r\n        """Load AI models during initialization"""\r\n        try:\r\n            # Load TensorFlow/Keras model\r\n            self.detection_model = tf.keras.models.load_model(\'/path/to/detection_model\')\r\n            self.get_logger().info(\'AI model loaded successfully\')\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Failed to load AI model: {e}\')\r\n\r\n    def inference_callback(self, msg):\r\n        """Process incoming sensor data with AI models"""\r\n        try:\r\n            # Convert ROS image to OpenCV format\r\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\r\n\r\n            # Preprocess image for model\r\n            processed_image = self.preprocess_image(cv_image)\r\n\r\n            # Run inference\r\n            with torch.no_grad():  # For PyTorch models\r\n                prediction = self.classification_model(processed_image)\r\n\r\n            # Publish results\r\n            result_msg = String()\r\n            result_msg.data = str(prediction.cpu().numpy().tolist())\r\n            self.result_publisher.publish(result_msg)\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Inference error: {e}\')\r\n\r\n    def preprocess_image(self, image):\r\n        """Preprocess image for AI model input"""\r\n        # Resize, normalize, convert to tensor as needed by your model\r\n        resized = cv2.resize(image, (224, 224))\r\n        normalized = resized / 255.0\r\n        tensor = torch.tensor(normalized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\r\n        return tensor\n'})}),"\n",(0,o.jsx)(n.h3,{id:"real-time-performance-considerations",children:"Real-time Performance Considerations"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Threading"}),": Use separate threads for AI inference to avoid blocking the ROS communication loop:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import threading\r\nimport queue\r\n\r\nclass ThreadedAINode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'threaded_ai_node\')\r\n\r\n        # Queue for passing data between threads\r\n        self.data_queue = queue.Queue(maxsize=10)\r\n\r\n        # Start AI processing thread\r\n        self.ai_thread = threading.Thread(target=self.ai_processing_loop)\r\n        self.ai_thread.daemon = True\r\n        self.ai_thread.start()\r\n\r\n        # Subscribe to sensor data\r\n        self.subscription = self.create_subscription(\r\n            Image,\r\n            \'/camera/image_raw\',\r\n            self.sensor_callback,\r\n            10)\r\n\r\n    def sensor_callback(self, msg):\r\n        """Called in main thread - just queue the data"""\r\n        try:\r\n            self.data_queue.put_nowait(msg)\r\n        except queue.Full:\r\n            self.get_logger().warn(\'Data queue full, dropping frame\')\r\n\r\n    def ai_processing_loop(self):\r\n        """Run in separate thread - handles AI processing"""\r\n        while rclpy.ok():\r\n            try:\r\n                # Get data from queue (blocks until available)\r\n                msg = self.data_queue.get(timeout=0.1)\r\n\r\n                # Process with AI model\r\n                result = self.process_with_ai(msg)\r\n\r\n                # Publish result in main thread using call later\r\n                self.call_in_main_thread(result)\r\n\r\n            except queue.Empty:\r\n                continue\r\n            except Exception as e:\r\n                self.get_logger().error(f\'AI processing error: {e}\')\n'})}),"\n",(0,o.jsx)(n.h2,{id:"services-for-synchronous-operations",children:"Services for Synchronous Operations"}),"\n",(0,o.jsx)(n.p,{children:"AI agents can provide services to other nodes:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from example_interfaces.srv import SetBool, Trigger\r\n\r\nclass AIServiceNode(Node):\r\n    def __init__(self):\r\n        super().__init__('ai_service_node')\r\n\r\n        # Service to enable/disable AI processing\r\n        self.enable_service = self.create_service(\r\n            SetBool,\r\n            'enable_ai_processing',\r\n            self.enable_callback)\r\n\r\n        self.ai_enabled = True\r\n\r\n    def enable_callback(self, request, response):\r\n        \"\"\"Handle enable/disable request\"\"\"\r\n        self.ai_enabled = request.data\r\n        response.success = True\r\n        response.message = f\"AI processing {'enabled' if self.ai_enabled else 'disabled'}\"\r\n        self.get_logger().info(response.message)\r\n        return response\n"})}),"\n",(0,o.jsx)(n.h2,{id:"actions-for-long-running-tasks",children:"Actions for Long-Running Tasks"}),"\n",(0,o.jsx)(n.p,{children:"For tasks that take significant time, ROS 2 actions are more appropriate:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from rclpy.action import ActionServer\r\nfrom example_interfaces.action import Fibonacci\r\n\r\nclass AIActionServer(Node):\r\n    def __init__(self):\r\n        super().__init__('ai_action_server')\r\n\r\n        self._action_server = ActionServer(\r\n            self,\r\n            Fibonacci,\r\n            'ai_fibonacci',\r\n            execute_callback=self.execute_callback)\r\n\r\n    async def execute_callback(self, goal_handle):\r\n        \"\"\"Execute the goal (runs in separate thread)\"\"\"\r\n        self.get_logger().info('Executing goal...')\r\n\r\n        feedback_msg = Fibonacci.Feedback()\r\n        feedback_msg.sequence = [0, 1]\r\n\r\n        for i in range(1, goal_handle.request.order):\r\n            # Simulate AI processing time\r\n            time.sleep(0.1)\r\n\r\n            feedback_msg.sequence.append(\r\n                feedback_msg.sequence[i] + feedback_msg.sequence[i-1])\r\n\r\n            # Publish feedback\r\n            goal_handle.publish_feedback(feedback_msg)\r\n\r\n        goal_handle.succeed()\r\n        result = Fibonacci.Result()\r\n        result.sequence = feedback_msg.sequence\r\n        self.get_logger().info('Goal succeeded')\r\n\r\n        return result\n"})}),"\n",(0,o.jsx)(n.h2,{id:"example-complete-ai-ros-integration",children:"Example: Complete AI-ROS Integration"}),"\n",(0,o.jsx)(n.p,{children:"Here's an example showing an AI agent controlling a humanoid robot:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import JointState, Image, Imu\r\nfrom geometry_msgs.msg import Twist\r\nfrom std_msgs.msg import String\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport threading\r\nimport queue\r\nfrom cv_bridge import CvBridge\r\n\r\nclass HumanoidAIController(Node):\r\n    def __init__(self):\r\n        super().__init__(\'humanoid_ai_controller\')\r\n\r\n        # Initialize components\r\n        self.bridge = CvBridge()\r\n        self.data_queue = queue.Queue(maxsize=5)\r\n\r\n        # Load AI model for movement planning\r\n        try:\r\n            self.movement_model = tf.keras.models.load_model(\'/path/to/movement_model\')\r\n            self.get_logger().info(\'Movement model loaded successfully\')\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Failed to load movement model: {e}\')\r\n            self.movement_model = None\r\n\r\n        # Subscribe to sensor data\r\n        self.joint_state_sub = self.create_subscription(\r\n            JointState,\r\n            \'/joint_states\',\r\n            self.joint_state_callback,\r\n            10)\r\n\r\n        # Publishers for control commands\r\n        self.cmd_vel_pub = self.create_publisher(\r\n            Twist,\r\n            \'/cmd_vel\',\r\n            10)\r\n\r\n        self.status_pub = self.create_publisher(\r\n            String,\r\n            \'/ai/status\',\r\n            10)\r\n\r\n        # Timer for periodic AI decision making\r\n        self.control_timer = self.create_timer(0.1, self.ai_control_loop)\r\n\r\n        # Store current sensor data\r\n        self.current_joint_positions = None\r\n\r\n    def joint_state_callback(self, msg):\r\n        """Store current joint positions"""\r\n        self.current_joint_positions = np.array(msg.position)\r\n\r\n    def ai_control_loop(self):\r\n        """Main control loop running at 10Hz"""\r\n        if self.current_joint_positions is not None and self.movement_model is not None:\r\n            try:\r\n                # Prepare input for movement model\r\n                input_data = self.prepare_movement_input()\r\n\r\n                # Get AI prediction for next movement\r\n                target_positions = self.movement_model.predict(\r\n                    np.expand_dims(input_data, axis=0)\r\n                )[0]\r\n\r\n                # Send trajectory command (simplified)\r\n                self.send_velocity_command(target_positions[0], 0, target_positions[1])\r\n\r\n                # Publish status\r\n                status_msg = String()\r\n                status_msg.data = f"Controlling robot with AI"\r\n                self.status_pub.publish(status_msg)\r\n\r\n            except Exception as e:\r\n                self.get_logger().error(f\'Control loop error: {e}\')\r\n\r\n    def prepare_movement_input(self):\r\n        """Prepare input data for movement model"""\r\n        # Combine joint positions and other relevant information\r\n        input_data = np.concatenate([\r\n            self.current_joint_positions[:2],  # Using first 2 joints as example\r\n        ])\r\n        return input_data\r\n\r\n    def send_velocity_command(self, linear_x, angular_z):\r\n        """Send velocity command"""\r\n        msg = Twist()\r\n        msg.linear.x = linear_x\r\n        msg.angular.z = angular_z\r\n        self.cmd_vel_pub.publish(msg)\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n\r\n    ai_controller = HumanoidAIController()\r\n\r\n    # Use multi-threaded executor to handle callbacks and AI processing\r\n    executor = MultiThreadedExecutor()\r\n    executor.add_node(ai_controller)\r\n\r\n    try:\r\n        executor.spin()\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        ai_controller.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"best-practices-for-ai-ros-integration",children:"Best Practices for AI-ROS Integration"}),"\n",(0,o.jsx)(n.h3,{id:"design-patterns",children:"Design Patterns"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Separation of Concerns"}),": Keep AI logic separate from ROS communication logic"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Create dedicated classes for AI processing"}),"\n",(0,o.jsx)(n.li,{children:"Use ROS nodes primarily for communication and coordination"}),"\n",(0,o.jsx)(n.li,{children:"Implement clear interfaces between AI components and ROS components"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Error Handling"}),": Implement robust error handling for both AI and ROS components"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Handle model loading failures gracefully"}),"\n",(0,o.jsx)(n.li,{children:"Implement fallback behaviors when AI models fail"}),"\n",(0,o.jsx)(n.li,{children:"Use ROS logging appropriately for debugging"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Resource Management"}),": Monitor and manage computational resources"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Implement resource monitoring to detect system overload"}),"\n",(0,o.jsx)(n.li,{children:"Use appropriate QoS settings for different types of data"}),"\n",(0,o.jsx)(n.li,{children:"Consider computational requirements when designing AI models"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Asynchronous Processing"}),": Use separate threads or async patterns for AI inference"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Implement proper thread synchronization"}),"\n",(0,o.jsx)(n.li,{children:"Use queues for safe data passing between threads"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Message Filtering"}),": Only process messages at the required frequency"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Implement message throttling when appropriate"}),"\n",(0,o.jsx)(n.li,{children:"Use time-based filtering to reduce processing load"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Model Optimization"}),": Optimize AI models for the target hardware"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Use quantization to reduce model size and improve speed"}),"\n",(0,o.jsx)(n.li,{children:"Implement model pruning to remove unnecessary weights"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"rclpy"})," provides a powerful bridge between Python-based AI algorithms and ROS 2 robotic systems. By understanding how to create publishers, subscribers, services, and actions with ",(0,o.jsx)(n.code,{children:"rclpy"}),", you can integrate sophisticated AI models with robotic hardware control. The key is to balance the computational requirements of AI algorithms with the real-time constraints of robotic systems."]}),"\n",(0,o.jsx)(n.p,{children:"In the next section, we'll explore URDF (Unified Robot Description Format) and how it describes the structure of humanoid robots."})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453(e,n,r){r.d(n,{R:()=>t,x:()=>l});var s=r(6540);const o={},i=s.createContext(o);function t(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);