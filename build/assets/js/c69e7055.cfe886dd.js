"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[113],{7133(e,n,s){s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>m,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module-1-ros2/ai-ros-integration","title":"Connecting AI Agents to ROS Controllers","description":"Using Python and rclpy to connect AI algorithms to ROS 2 systems","source":"@site/docs/module-1-ros2/ai-ros-integration.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/ai-ros-integration","permalink":"/my-book/docs/module-1-ros2/ai-ros-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/my-book/edit/main/docs/module-1-ros2/ai-ros-integration.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Connecting AI Agents to ROS Controllers","description":"Using Python and rclpy to connect AI algorithms to ROS 2 systems"},"sidebar":"tutorialSidebar","previous":{"title":"Nodes, Topics, and Services","permalink":"/my-book/docs/module-1-ros2/nodes-topics-services"},"next":{"title":"URDF and Humanoid Robot Structure","permalink":"/my-book/docs/module-1-ros2/urdf-structure"}}');var o=s(4848),i=s(8453);const t={sidebar_position:6,title:"Connecting AI Agents to ROS Controllers",description:"Using Python and rclpy to connect AI algorithms to ROS 2 systems"},l="Connecting Python AI Agents to ROS Controllers using rclpy",a={},c=[{value:"Introduction to rclpy",id:"introduction-to-rclpy",level:2},{value:"Setting Up rclpy",id:"setting-up-rclpy",level:2},{value:"Creating Publishers and Subscribers",id:"creating-publishers-and-subscribers",level:2},{value:"Subscribers for Sensor Data",id:"subscribers-for-sensor-data",level:3},{value:"Publishers for Control Commands",id:"publishers-for-control-commands",level:3},{value:"Quality of Service (QoS) Configuration",id:"quality-of-service-qos-configuration",level:3},{value:"Integrating AI Models with ROS 2",id:"integrating-ai-models-with-ros-2",level:2},{value:"Loading AI Models",id:"loading-ai-models",level:3},{value:"Real-time Performance Considerations",id:"real-time-performance-considerations",level:3},{value:"Services for Synchronous Operations",id:"services-for-synchronous-operations",level:2},{value:"Actions for Long-Running Tasks",id:"actions-for-long-running-tasks",level:2},{value:"Example: Complete AI-ROS Integration",id:"example-complete-ai-ros-integration",level:2},{value:"Best Practices for AI-ROS Integration",id:"best-practices-for-ai-ros-integration",level:2},{value:"Design Patterns",id:"design-patterns",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"connecting-python-ai-agents-to-ros-controllers-using-rclpy",children:"Connecting Python AI Agents to ROS Controllers using rclpy"})}),"\n",(0,o.jsx)(n.h2,{id:"introduction-to-rclpy",children:"Introduction to rclpy"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"rclpy"})," is the Python client library for ROS 2, providing Python bindings for the ROS 2 client library (rcl). It enables Python-based AI agents to integrate with ROS 2-based robotic systems, creating a bridge between AI algorithms and robotic hardware control."]}),"\n",(0,o.jsxs)(n.p,{children:["Python has become the dominant language for AI development due to its rich ecosystem of libraries like TensorFlow, PyTorch, and scikit-learn. ",(0,o.jsx)(n.code,{children:"rclpy"})," leverages these advantages while maintaining compatibility with the broader ROS 2 ecosystem, making it ideal for integrating AI algorithms with robotic systems."]}),"\n",(0,o.jsx)(n.h2,{id:"setting-up-rclpy",children:"Setting Up rclpy"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"rclpy"})," is typically installed as part of a ROS 2 distribution. For most users, it's available after installing ROS 2 and sourcing the setup script:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"source /opt/ros/humble/setup.bash  # or your ROS 2 distribution\n"})}),"\n",(0,o.jsxs)(n.p,{children:["A typical ",(0,o.jsx)(n.code,{children:"rclpy"})," node follows this structure:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\n\nclass AIControllerNode(Node):\n    def __init__(self):\n        super().__init__('ai_controller_node')\n        # Initialize publishers, subscribers, services, etc.\n        # Set up AI model if needed\n        # Configure parameters\n\ndef main():\n    rclpy.init()\n    node = AIControllerNode()\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n"})}),"\n",(0,o.jsx)(n.h2,{id:"creating-publishers-and-subscribers",children:"Creating Publishers and Subscribers"}),"\n",(0,o.jsx)(n.h3,{id:"subscribers-for-sensor-data",children:"Subscribers for Sensor Data"}),"\n",(0,o.jsx)(n.p,{children:"AI agents need to receive sensor data to perceive the environment:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from sensor_msgs.msg import Image, LaserScan, Imu, JointState\nfrom std_msgs.msg import String\n\nclass PerceptionNode(Node):\n    def __init__(self):\n        super().__init__('perception_node')\n\n        # Subscribe to camera data\n        self.image_subscription = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.image_callback,\n            10)  # QoS history depth\n\n        # Subscribe to joint states\n        self.joint_subscription = self.create_subscription(\n            JointState,\n            '/joint_states',\n            self.joint_callback,\n            10)\n\n        # Store the latest sensor data\n        self.latest_image = None\n        self.latest_joints = None\n\n    def image_callback(self, msg):\n        self.latest_image = msg\n        # Process image data with AI algorithm\n\n    def joint_callback(self, msg):\n        self.latest_joints = msg\n        # Process joint state data\n"})}),"\n",(0,o.jsx)(n.h3,{id:"publishers-for-control-commands",children:"Publishers for Control Commands"}),"\n",(0,o.jsx)(n.p,{children:"AI agents publish commands to control the robot:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import JointState\n\nclass AIControllerNode(Node):\n    def __init__(self):\n        super().__init__('ai_controller')\n\n        # Publisher for robot velocity commands\n        self.cmd_vel_publisher = self.create_publisher(\n            Twist,\n            '/cmd_vel',\n            10)\n\n        # Publisher for joint position commands\n        self.joint_cmd_publisher = self.create_publisher(\n            JointState,\n            '/joint_group_position_controller/commands',\n            10)\n\n    def send_velocity_command(self, linear_x, linear_y, angular_z):\n        msg = Twist()\n        msg.linear.x = linear_x\n        msg.linear.y = linear_y\n        msg.angular.z = angular_z\n        self.cmd_vel_publisher.publish(msg)\n\n    def send_joint_positions(self, joint_names, positions):\n        msg = JointState()\n        msg.name = joint_names\n        msg.position = positions\n        self.joint_cmd_publisher.publish(msg)\n"})}),"\n",(0,o.jsx)(n.h3,{id:"quality-of-service-qos-configuration",children:"Quality of Service (QoS) Configuration"}),"\n",(0,o.jsx)(n.p,{children:"Configure QoS settings to match your application's requirements:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from rclpy.qos import QoSProfile, ReliabilityPolicy\n\n# For critical control commands - reliable delivery\ncontrol_qos = QoSProfile(\n    depth=10,\n    reliability=ReliabilityPolicy.RELIABLE,\n    history=HistoryPolicy.KEEP_LAST\n)\n\n# Create publisher with custom QoS\nself.control_publisher = self.create_publisher(\n    Twist,\n    '/cmd_vel',\n    qos_profile=control_qos\n)\n"})}),"\n",(0,o.jsx)(n.h2,{id:"integrating-ai-models-with-ros-2",children:"Integrating AI Models with ROS 2"}),"\n",(0,o.jsx)(n.h3,{id:"loading-ai-models",children:"Loading AI Models"}),"\n",(0,o.jsx)(n.p,{children:"AI models can be loaded within ROS 2 nodes for real-time inference:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import tensorflow as tf\nimport torch\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\n\nclass AIInferenceNode(Node):\n    def __init__(self):\n        super().__init__(\'ai_inference_node\')\n\n        # Initialize OpenCV bridge for image conversion\n        self.bridge = CvBridge()\n\n        # Load pre-trained models\n        self.load_models()\n\n        # Subscribe to sensor data\n        self.image_subscription = self.create_subscription(\n            Image,\n            \'/camera/image_raw\',\n            self.inference_callback,\n            10)\n\n        # Publisher for inference results\n        self.result_publisher = self.create_publisher(\n            String,\n            \'/ai/inference_result\',\n            10)\n\n    def load_models(self):\n        """Load AI models during initialization"""\n        try:\n            # Load TensorFlow/Keras model\n            self.detection_model = tf.keras.models.load_model(\'/path/to/detection_model\')\n            self.get_logger().info(\'AI model loaded successfully\')\n        except Exception as e:\n            self.get_logger().error(f\'Failed to load AI model: {e}\')\n\n    def inference_callback(self, msg):\n        """Process incoming sensor data with AI models"""\n        try:\n            # Convert ROS image to OpenCV format\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\n\n            # Preprocess image for model\n            processed_image = self.preprocess_image(cv_image)\n\n            # Run inference\n            with torch.no_grad():  # For PyTorch models\n                prediction = self.classification_model(processed_image)\n\n            # Publish results\n            result_msg = String()\n            result_msg.data = str(prediction.cpu().numpy().tolist())\n            self.result_publisher.publish(result_msg)\n        except Exception as e:\n            self.get_logger().error(f\'Inference error: {e}\')\n\n    def preprocess_image(self, image):\n        """Preprocess image for AI model input"""\n        # Resize, normalize, convert to tensor as needed by your model\n        resized = cv2.resize(image, (224, 224))\n        normalized = resized / 255.0\n        tensor = torch.tensor(normalized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n        return tensor\n'})}),"\n",(0,o.jsx)(n.h3,{id:"real-time-performance-considerations",children:"Real-time Performance Considerations"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Threading"}),": Use separate threads for AI inference to avoid blocking the ROS communication loop:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import threading\nimport queue\n\nclass ThreadedAINode(Node):\n    def __init__(self):\n        super().__init__(\'threaded_ai_node\')\n\n        # Queue for passing data between threads\n        self.data_queue = queue.Queue(maxsize=10)\n\n        # Start AI processing thread\n        self.ai_thread = threading.Thread(target=self.ai_processing_loop)\n        self.ai_thread.daemon = True\n        self.ai_thread.start()\n\n        # Subscribe to sensor data\n        self.subscription = self.create_subscription(\n            Image,\n            \'/camera/image_raw\',\n            self.sensor_callback,\n            10)\n\n    def sensor_callback(self, msg):\n        """Called in main thread - just queue the data"""\n        try:\n            self.data_queue.put_nowait(msg)\n        except queue.Full:\n            self.get_logger().warn(\'Data queue full, dropping frame\')\n\n    def ai_processing_loop(self):\n        """Run in separate thread - handles AI processing"""\n        while rclpy.ok():\n            try:\n                # Get data from queue (blocks until available)\n                msg = self.data_queue.get(timeout=0.1)\n\n                # Process with AI model\n                result = self.process_with_ai(msg)\n\n                # Publish result in main thread using call later\n                self.call_in_main_thread(result)\n\n            except queue.Empty:\n                continue\n            except Exception as e:\n                self.get_logger().error(f\'AI processing error: {e}\')\n'})}),"\n",(0,o.jsx)(n.h2,{id:"services-for-synchronous-operations",children:"Services for Synchronous Operations"}),"\n",(0,o.jsx)(n.p,{children:"AI agents can provide services to other nodes:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from example_interfaces.srv import SetBool, Trigger\n\nclass AIServiceNode(Node):\n    def __init__(self):\n        super().__init__('ai_service_node')\n\n        # Service to enable/disable AI processing\n        self.enable_service = self.create_service(\n            SetBool,\n            'enable_ai_processing',\n            self.enable_callback)\n\n        self.ai_enabled = True\n\n    def enable_callback(self, request, response):\n        \"\"\"Handle enable/disable request\"\"\"\n        self.ai_enabled = request.data\n        response.success = True\n        response.message = f\"AI processing {'enabled' if self.ai_enabled else 'disabled'}\"\n        self.get_logger().info(response.message)\n        return response\n"})}),"\n",(0,o.jsx)(n.h2,{id:"actions-for-long-running-tasks",children:"Actions for Long-Running Tasks"}),"\n",(0,o.jsx)(n.p,{children:"For tasks that take significant time, ROS 2 actions are more appropriate:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from rclpy.action import ActionServer\nfrom example_interfaces.action import Fibonacci\n\nclass AIActionServer(Node):\n    def __init__(self):\n        super().__init__('ai_action_server')\n\n        self._action_server = ActionServer(\n            self,\n            Fibonacci,\n            'ai_fibonacci',\n            execute_callback=self.execute_callback)\n\n    async def execute_callback(self, goal_handle):\n        \"\"\"Execute the goal (runs in separate thread)\"\"\"\n        self.get_logger().info('Executing goal...')\n\n        feedback_msg = Fibonacci.Feedback()\n        feedback_msg.sequence = [0, 1]\n\n        for i in range(1, goal_handle.request.order):\n            # Simulate AI processing time\n            time.sleep(0.1)\n\n            feedback_msg.sequence.append(\n                feedback_msg.sequence[i] + feedback_msg.sequence[i-1])\n\n            # Publish feedback\n            goal_handle.publish_feedback(feedback_msg)\n\n        goal_handle.succeed()\n        result = Fibonacci.Result()\n        result.sequence = feedback_msg.sequence\n        self.get_logger().info('Goal succeeded')\n\n        return result\n"})}),"\n",(0,o.jsx)(n.h2,{id:"example-complete-ai-ros-integration",children:"Example: Complete AI-ROS Integration"}),"\n",(0,o.jsx)(n.p,{children:"Here's an example showing an AI agent controlling a humanoid robot:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState, Image, Imu\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import String\nimport numpy as np\nimport tensorflow as tf\nimport threading\nimport queue\nfrom cv_bridge import CvBridge\n\nclass HumanoidAIController(Node):\n    def __init__(self):\n        super().__init__(\'humanoid_ai_controller\')\n\n        # Initialize components\n        self.bridge = CvBridge()\n        self.data_queue = queue.Queue(maxsize=5)\n\n        # Load AI model for movement planning\n        try:\n            self.movement_model = tf.keras.models.load_model(\'/path/to/movement_model\')\n            self.get_logger().info(\'Movement model loaded successfully\')\n        except Exception as e:\n            self.get_logger().error(f\'Failed to load movement model: {e}\')\n            self.movement_model = None\n\n        # Subscribe to sensor data\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            \'/joint_states\',\n            self.joint_state_callback,\n            10)\n\n        # Publishers for control commands\n        self.cmd_vel_pub = self.create_publisher(\n            Twist,\n            \'/cmd_vel\',\n            10)\n\n        self.status_pub = self.create_publisher(\n            String,\n            \'/ai/status\',\n            10)\n\n        # Timer for periodic AI decision making\n        self.control_timer = self.create_timer(0.1, self.ai_control_loop)\n\n        # Store current sensor data\n        self.current_joint_positions = None\n\n    def joint_state_callback(self, msg):\n        """Store current joint positions"""\n        self.current_joint_positions = np.array(msg.position)\n\n    def ai_control_loop(self):\n        """Main control loop running at 10Hz"""\n        if self.current_joint_positions is not None and self.movement_model is not None:\n            try:\n                # Prepare input for movement model\n                input_data = self.prepare_movement_input()\n\n                # Get AI prediction for next movement\n                target_positions = self.movement_model.predict(\n                    np.expand_dims(input_data, axis=0)\n                )[0]\n\n                # Send trajectory command (simplified)\n                self.send_velocity_command(target_positions[0], 0, target_positions[1])\n\n                # Publish status\n                status_msg = String()\n                status_msg.data = f"Controlling robot with AI"\n                self.status_pub.publish(status_msg)\n\n            except Exception as e:\n                self.get_logger().error(f\'Control loop error: {e}\')\n\n    def prepare_movement_input(self):\n        """Prepare input data for movement model"""\n        # Combine joint positions and other relevant information\n        input_data = np.concatenate([\n            self.current_joint_positions[:2],  # Using first 2 joints as example\n        ])\n        return input_data\n\n    def send_velocity_command(self, linear_x, angular_z):\n        """Send velocity command"""\n        msg = Twist()\n        msg.linear.x = linear_x\n        msg.angular.z = angular_z\n        self.cmd_vel_pub.publish(msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    ai_controller = HumanoidAIController()\n\n    # Use multi-threaded executor to handle callbacks and AI processing\n    executor = MultiThreadedExecutor()\n    executor.add_node(ai_controller)\n\n    try:\n        executor.spin()\n    except KeyboardInterrupt:\n        pass\n    finally:\n        ai_controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"best-practices-for-ai-ros-integration",children:"Best Practices for AI-ROS Integration"}),"\n",(0,o.jsx)(n.h3,{id:"design-patterns",children:"Design Patterns"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Separation of Concerns"}),": Keep AI logic separate from ROS communication logic"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Create dedicated classes for AI processing"}),"\n",(0,o.jsx)(n.li,{children:"Use ROS nodes primarily for communication and coordination"}),"\n",(0,o.jsx)(n.li,{children:"Implement clear interfaces between AI components and ROS components"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Error Handling"}),": Implement robust error handling for both AI and ROS components"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Handle model loading failures gracefully"}),"\n",(0,o.jsx)(n.li,{children:"Implement fallback behaviors when AI models fail"}),"\n",(0,o.jsx)(n.li,{children:"Use ROS logging appropriately for debugging"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Resource Management"}),": Monitor and manage computational resources"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Implement resource monitoring to detect system overload"}),"\n",(0,o.jsx)(n.li,{children:"Use appropriate QoS settings for different types of data"}),"\n",(0,o.jsx)(n.li,{children:"Consider computational requirements when designing AI models"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Asynchronous Processing"}),": Use separate threads or async patterns for AI inference"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Implement proper thread synchronization"}),"\n",(0,o.jsx)(n.li,{children:"Use queues for safe data passing between threads"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Message Filtering"}),": Only process messages at the required frequency"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Implement message throttling when appropriate"}),"\n",(0,o.jsx)(n.li,{children:"Use time-based filtering to reduce processing load"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Model Optimization"}),": Optimize AI models for the target hardware"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Use quantization to reduce model size and improve speed"}),"\n",(0,o.jsx)(n.li,{children:"Implement model pruning to remove unnecessary weights"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"rclpy"})," provides a powerful bridge between Python-based AI algorithms and ROS 2 robotic systems. By understanding how to create publishers, subscribers, services, and actions with ",(0,o.jsx)(n.code,{children:"rclpy"}),", you can integrate sophisticated AI models with robotic hardware control. The key is to balance the computational requirements of AI algorithms with the real-time constraints of robotic systems."]}),"\n",(0,o.jsx)(n.p,{children:"In the next section, we'll explore URDF (Unified Robot Description Format) and how it describes the structure of humanoid robots."})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453(e,n,s){s.d(n,{R:()=>t,x:()=>l});var r=s(6540);const o={},i=r.createContext(o);function t(e){const n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);