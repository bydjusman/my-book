<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-3-ai-robot-brain/synthetic-data" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Synthetic Data Generation | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://my-book-smoky-alpha.vercel.app/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://my-book-smoky-alpha.vercel.app/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://my-book-smoky-alpha.vercel.app/docs/module-3-ai-robot-brain/synthetic-data"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Synthetic Data Generation | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="How Isaac Sim creates training data for perception systems"><meta data-rh="true" property="og:description" content="How Isaac Sim creates training data for perception systems"><link data-rh="true" rel="icon" href="/img/logo.png"><link data-rh="true" rel="canonical" href="https://my-book-smoky-alpha.vercel.app/docs/module-3-ai-robot-brain/synthetic-data"><link data-rh="true" rel="alternate" href="https://my-book-smoky-alpha.vercel.app/docs/module-3-ai-robot-brain/synthetic-data" hreflang="en"><link data-rh="true" rel="alternate" href="https://my-book-smoky-alpha.vercel.app/docs/module-3-ai-robot-brain/synthetic-data" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Synthetic Data Generation","item":"https://my-book-smoky-alpha.vercel.app/docs/module-3-ai-robot-brain/synthetic-data"}]}</script><link rel="stylesheet" href="/assets/css/styles.6579749f.css">
<script src="/assets/js/runtime~main.da2f1c3e.js" defer="defer"></script>
<script src="/assets/js/main.efa7964b.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="Robotics Book Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="Robotics Book Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/bydjusman/my-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-1-ros2/"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-2-simulation/"><span title="Module 2: The Digital Twin (Gazebo &amp; Unity)" class="categoryLinkLabel_W154">Module 2: The Digital Twin (Gazebo &amp; Unity)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/module-3-ai-robot-brain/"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-3-ai-robot-brain/"><span title="Module 3 - The AI-Robot Brain" class="linkLabel_WmDU">Module 3 - The AI-Robot Brain</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-3-ai-robot-brain/isaac-sim"><span title="NVIDIA Isaac Sim" class="linkLabel_WmDU">NVIDIA Isaac Sim</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-3-ai-robot-brain/isaac-ros"><span title="Isaac ROS Integration" class="linkLabel_WmDU">Isaac ROS Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/module-3-ai-robot-brain/synthetic-data"><span title="Synthetic Data Generation" class="linkLabel_WmDU">Synthetic Data Generation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-3-ai-robot-brain/vslam-navigation"><span title="Visual SLAM &amp; Navigation" class="linkLabel_WmDU">Visual SLAM &amp; Navigation</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-4-vla/"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Synthetic Data Generation</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Synthetic Data Generation: Training AI with Virtual Worlds</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-challenge-of-real-world-data">The Challenge of Real-World Data<a href="#the-challenge-of-real-world-data" class="hash-link" aria-label="Direct link to The Challenge of Real-World Data" title="Direct link to The Challenge of Real-World Data" translate="no">â€‹</a></h2>
<p>Training AI perception systems for humanoid robots requires vast amounts of labeled data. In the real world, collecting this data is incredibly challenging:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="time-and-cost-constraints">Time and Cost Constraints<a href="#time-and-cost-constraints" class="hash-link" aria-label="Direct link to Time and Cost Constraints" title="Direct link to Time and Cost Constraints" translate="no">â€‹</a></h3>
<p>Real-world data collection is extremely time-consuming and expensive:</p>
<ul>
<li class="">Hours of manual annotation are required for each image</li>
<li class="">Specialized equipment and personnel are needed</li>
<li class="">Safety considerations limit when and where data can be collected</li>
<li class="">Weather and lighting conditions affect data quality and consistency</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="limited-scenario-coverage">Limited Scenario Coverage<a href="#limited-scenario-coverage" class="hash-link" aria-label="Direct link to Limited Scenario Coverage" title="Direct link to Limited Scenario Coverage" translate="no">â€‹</a></h3>
<p>Real-world data collection is constrained by practical limitations:</p>
<ul>
<li class="">Dangerous scenarios cannot be safely tested</li>
<li class="">Rare events may take years to encounter naturally</li>
<li class="">Privacy concerns limit data collection in some environments</li>
<li class="">Seasonal or time-specific conditions are difficult to reproduce</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="quality-and-consistency-issues">Quality and Consistency Issues<a href="#quality-and-consistency-issues" class="hash-link" aria-label="Direct link to Quality and Consistency Issues" title="Direct link to Quality and Consistency Issues" translate="no">â€‹</a></h3>
<p>Real-world data often has quality problems:</p>
<ul>
<li class="">Inconsistent lighting and weather conditions</li>
<li class="">Varying camera angles and sensor quality</li>
<li class="">Incomplete or inaccurate annotations</li>
<li class="">Bias toward commonly encountered scenarios</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-synthetic-data">What is Synthetic Data?<a href="#what-is-synthetic-data" class="hash-link" aria-label="Direct link to What is Synthetic Data?" title="Direct link to What is Synthetic Data?" translate="no">â€‹</a></h2>
<p>Synthetic data refers to information generated by computer simulation rather than collected from the real world. In robotics, synthetic data is created by running virtual robots through simulated environments and capturing sensor data along with perfect ground truth information.</p>
<p>Think of synthetic data as a virtual laboratory where robots can experience thousands of scenarios in minutes, with every detail perfectly recorded and labeled. Unlike real-world data collection, synthetic data generation can run continuously, creating diverse, varied, and perfectly annotated datasets at scale.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-isaac-sim-generates-synthetic-data">How Isaac Sim Generates Synthetic Data<a href="#how-isaac-sim-generates-synthetic-data" class="hash-link" aria-label="Direct link to How Isaac Sim Generates Synthetic Data" title="Direct link to How Isaac Sim Generates Synthetic Data" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="photorealistic-rendering-pipeline">Photorealistic Rendering Pipeline<a href="#photorealistic-rendering-pipeline" class="hash-link" aria-label="Direct link to Photorealistic Rendering Pipeline" title="Direct link to Photorealistic Rendering Pipeline" translate="no">â€‹</a></h3>
<p>Isaac Sim uses advanced rendering technology to create images that closely match real-world camera data:</p>
<ul>
<li class=""><strong>Ray tracing</strong>: Accurate simulation of light behavior for realistic images</li>
<li class=""><strong>Material properties</strong>: Detailed surface characteristics that affect appearance</li>
<li class=""><strong>Lighting models</strong>: Realistic simulation of natural and artificial lighting</li>
<li class=""><strong>Sensor simulation</strong>: Accurate modeling of camera properties and limitations</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ground-truth-generation">Ground Truth Generation<a href="#ground-truth-generation" class="hash-link" aria-label="Direct link to Ground Truth Generation" title="Direct link to Ground Truth Generation" translate="no">â€‹</a></h3>
<p>One of the key advantages of synthetic data is perfect ground truth:</p>
<ul>
<li class=""><strong>Semantic segmentation</strong>: Every pixel labeled with object class</li>
<li class=""><strong>Instance segmentation</strong>: Individual object identification</li>
<li class=""><strong>Depth information</strong>: Accurate distance measurements for every point</li>
<li class=""><strong>3D pose information</strong>: Precise position and orientation of objects</li>
<li class=""><strong>Bounding boxes</strong>: Perfectly accurate object localization</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="automated-annotation">Automated Annotation<a href="#automated-annotation" class="hash-link" aria-label="Direct link to Automated Annotation" title="Direct link to Automated Annotation" translate="no">â€‹</a></h3>
<p>Synthetic data comes with automatic, perfect annotations:</p>
<ul>
<li class="">No manual labeling required</li>
<li class="">Consistent annotation quality across all samples</li>
<li class="">Multiple annotation types available simultaneously</li>
<li class="">No human error in the labeling process</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="benefits-of-synthetic-data-for-perception-training">Benefits of Synthetic Data for Perception Training<a href="#benefits-of-synthetic-data-for-perception-training" class="hash-link" aria-label="Direct link to Benefits of Synthetic Data for Perception Training" title="Direct link to Benefits of Synthetic Data for Perception Training" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="unlimited-data-generation">Unlimited Data Generation<a href="#unlimited-data-generation" class="hash-link" aria-label="Direct link to Unlimited Data Generation" title="Direct link to Unlimited Data Generation" translate="no">â€‹</a></h3>
<p>Synthetic data can be generated continuously and at scale:</p>
<ul>
<li class="">Millions of training samples can be created in hours</li>
<li class="">No physical constraints on data collection</li>
<li class="">Consistent data quality and format</li>
<li class="">Cost-effective at scale</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="controlled-variation">Controlled Variation<a href="#controlled-variation" class="hash-link" aria-label="Direct link to Controlled Variation" title="Direct link to Controlled Variation" translate="no">â€‹</a></h3>
<p>Synthetic environments allow systematic variation of parameters:</p>
<ul>
<li class="">Lighting conditions: time of day, weather, artificial lighting</li>
<li class="">Object appearances: colors, textures, materials</li>
<li class="">Environmental conditions: indoor, outdoor, cluttered, sparse</li>
<li class="">Camera properties: angles, resolution, noise characteristics</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="perfect-annotations">Perfect Annotations<a href="#perfect-annotations" class="hash-link" aria-label="Direct link to Perfect Annotations" title="Direct link to Perfect Annotations" translate="no">â€‹</a></h3>
<p>Synthetic data provides flawless ground truth information:</p>
<ul>
<li class="">Pixel-perfect segmentation masks</li>
<li class="">Accurate 3D object poses</li>
<li class="">Consistent labeling across all samples</li>
<li class="">Multiple annotation types available</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="edge-case-generation">Edge Case Generation<a href="#edge-case-generation" class="hash-link" aria-label="Direct link to Edge Case Generation" title="Direct link to Edge Case Generation" translate="no">â€‹</a></h3>
<p>Synthetic environments can deliberately create challenging scenarios:</p>
<ul>
<li class="">Unusual lighting conditions</li>
<li class="">Complex occlusions</li>
<li class="">Rare object configurations</li>
<li class="">Adverse weather effects</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="use-cases-for-perception-training">Use Cases for Perception Training<a href="#use-cases-for-perception-training" class="hash-link" aria-label="Direct link to Use Cases for Perception Training" title="Direct link to Use Cases for Perception Training" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="object-detection-and-recognition">Object Detection and Recognition<a href="#object-detection-and-recognition" class="hash-link" aria-label="Direct link to Object Detection and Recognition" title="Direct link to Object Detection and Recognition" translate="no">â€‹</a></h3>
<p>Synthetic data is ideal for training object detection systems:</p>
<ul>
<li class=""><strong>Diverse object appearances</strong>: Objects can be rendered with various textures, colors, and lighting</li>
<li class=""><strong>Multiple viewpoints</strong>: Objects can be viewed from any angle</li>
<li class=""><strong>Cluttered scenes</strong>: Complex arrangements of objects can be systematically created</li>
<li class=""><strong>Occlusion handling</strong>: Objects can be partially hidden in controlled ways</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="semantic-segmentation">Semantic Segmentation<a href="#semantic-segmentation" class="hash-link" aria-label="Direct link to Semantic Segmentation" title="Direct link to Semantic Segmentation" translate="no">â€‹</a></h3>
<p>For pixel-level understanding of scenes:</p>
<ul>
<li class=""><strong>Perfect pixel labels</strong>: Every pixel is correctly labeled with object class</li>
<li class=""><strong>Consistent quality</strong>: No human error in segmentation labels</li>
<li class=""><strong>Multiple object classes</strong>: Many different object types can be included</li>
<li class=""><strong>Complex scenes</strong>: Detailed environments with many objects</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="depth-estimation">Depth Estimation<a href="#depth-estimation" class="hash-link" aria-label="Direct link to Depth Estimation" title="Direct link to Depth Estimation" translate="no">â€‹</a></h3>
<p>Synthetic data provides perfect depth information:</p>
<ul>
<li class=""><strong>Ground truth depth</strong>: Accurate distance measurements for every pixel</li>
<li class=""><strong>Multiple sensors</strong>: Different depth sensor types can be simulated</li>
<li class=""><strong>Challenging conditions</strong>: Low-light or textureless surfaces can be tested</li>
<li class=""><strong>Validation</strong>: Perfect depth maps for validating depth estimation algorithms</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="pose-estimation">Pose Estimation<a href="#pose-estimation" class="hash-link" aria-label="Direct link to Pose Estimation" title="Direct link to Pose Estimation" translate="no">â€‹</a></h3>
<p>For understanding object orientation and position:</p>
<ul>
<li class=""><strong>Accurate 3D poses</strong>: Precise position and orientation information</li>
<li class=""><strong>Multiple viewpoints</strong>: Objects can be observed from many angles</li>
<li class=""><strong>Articulated objects</strong>: Complex moving objects can be tracked</li>
<li class=""><strong>Multi-object scenes</strong>: Multiple objects in complex arrangements</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="domain-randomization">Domain Randomization<a href="#domain-randomization" class="hash-link" aria-label="Direct link to Domain Randomization" title="Direct link to Domain Randomization" translate="no">â€‹</a></h2>
<p>Domain randomization is a key technique in synthetic data generation that helps bridge the gap between simulation and reality:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="visual-domain-randomization">Visual Domain Randomization<a href="#visual-domain-randomization" class="hash-link" aria-label="Direct link to Visual Domain Randomization" title="Direct link to Visual Domain Randomization" translate="no">â€‹</a></h3>
<p>Randomizing visual properties to create robust models:</p>
<ul>
<li class=""><strong>Material properties</strong>: Surfaces with varying reflectance and texture</li>
<li class=""><strong>Lighting conditions</strong>: Random light positions, colors, and intensities</li>
<li class=""><strong>Camera parameters</strong>: Varying focal lengths, noise levels, and distortion</li>
<li class=""><strong>Weather effects</strong>: Simulated rain, fog, or other atmospheric conditions</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="physical-domain-randomization">Physical Domain Randomization<a href="#physical-domain-randomization" class="hash-link" aria-label="Direct link to Physical Domain Randomization" title="Direct link to Physical Domain Randomization" translate="no">â€‹</a></h3>
<p>Randomizing physical parameters for robustness:</p>
<ul>
<li class=""><strong>Friction coefficients</strong>: Varying surface properties</li>
<li class=""><strong>Mass properties</strong>: Different object weights and distributions</li>
<li class=""><strong>Dynamics parameters</strong>: Varying physical behaviors within realistic bounds</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="benefits-of-domain-randomization">Benefits of Domain Randomization<a href="#benefits-of-domain-randomization" class="hash-link" aria-label="Direct link to Benefits of Domain Randomization" title="Direct link to Benefits of Domain Randomization" translate="no">â€‹</a></h3>
<ul>
<li class=""><strong>Robustness</strong>: Models become less sensitive to specific visual features</li>
<li class=""><strong>Generalization</strong>: Better performance on real-world data</li>
<li class=""><strong>Reduced overfitting</strong>: Models don&#x27;t memorize specific simulation details</li>
<li class=""><strong>Transfer learning</strong>: Improved performance when moving to reality</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="combining-synthetic-and-real-data">Combining Synthetic and Real Data<a href="#combining-synthetic-and-real-data" class="hash-link" aria-label="Direct link to Combining Synthetic and Real Data" title="Direct link to Combining Synthetic and Real Data" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-augmentation">Data Augmentation<a href="#data-augmentation" class="hash-link" aria-label="Direct link to Data Augmentation" title="Direct link to Data Augmentation" translate="no">â€‹</a></h3>
<p>Synthetic data can augment limited real-world datasets:</p>
<ul>
<li class=""><strong>Class balance</strong>: Adding underrepresented object classes</li>
<li class=""><strong>Scenario coverage</strong>: Filling gaps in real-world data</li>
<li class=""><strong>Pre-training</strong>: Initial training on synthetic data before fine-tuning on real data</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="sim-to-real-transfer">Sim-to-Real Transfer<a href="#sim-to-real-transfer" class="hash-link" aria-label="Direct link to Sim-to-Real Transfer" title="Direct link to Sim-to-Real Transfer" translate="no">â€‹</a></h3>
<p>Techniques for improving transfer from synthetic to real data:</p>
<ul>
<li class=""><strong>Adversarial training</strong>: Training models to distinguish between synthetic and real data</li>
<li class=""><strong>Domain adaptation</strong>: Adapting synthetic-trained models to real-world conditions</li>
<li class=""><strong>Progressive domain transfer</strong>: Gradually introducing realistic elements to simulation</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hybrid-training-approaches">Hybrid Training Approaches<a href="#hybrid-training-approaches" class="hash-link" aria-label="Direct link to Hybrid Training Approaches" title="Direct link to Hybrid Training Approaches" translate="no">â€‹</a></h3>
<p>Effective strategies for combining both data types:</p>
<ul>
<li class=""><strong>Synthetic pre-training</strong>: Initial training on synthetic data for general features</li>
<li class=""><strong>Real-world fine-tuning</strong>: Refining on real data for specific conditions</li>
<li class=""><strong>Joint training</strong>: Training simultaneously on both datasets</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="quality-considerations">Quality Considerations<a href="#quality-considerations" class="hash-link" aria-label="Direct link to Quality Considerations" title="Direct link to Quality Considerations" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="simulation-fidelity">Simulation Fidelity<a href="#simulation-fidelity" class="hash-link" aria-label="Direct link to Simulation Fidelity" title="Direct link to Simulation Fidelity" translate="no">â€‹</a></h3>
<p>The quality of synthetic data depends on simulation accuracy:</p>
<ul>
<li class=""><strong>Visual fidelity</strong>: How closely rendered images match real cameras</li>
<li class=""><strong>Physical accuracy</strong>: How well physics simulation matches reality</li>
<li class=""><strong>Sensor modeling</strong>: How accurately sensors are simulated</li>
<li class=""><strong>Environmental modeling</strong>: How well real environments are replicated</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="validation-approaches">Validation Approaches<a href="#validation-approaches" class="hash-link" aria-label="Direct link to Validation Approaches" title="Direct link to Validation Approaches" translate="no">â€‹</a></h3>
<p>Ensuring synthetic data quality:</p>
<ul>
<li class=""><strong>Cross-validation</strong>: Comparing synthetic-trained models on real data</li>
<li class=""><strong>Physics validation</strong>: Ensuring simulated physics match reality</li>
<li class=""><strong>Sensor validation</strong>: Confirming simulated sensors behave like real ones</li>
<li class=""><strong>Expert review</strong>: Human validation of synthetic data quality</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="limitations-and-mitigation">Limitations and Mitigation<a href="#limitations-and-mitigation" class="hash-link" aria-label="Direct link to Limitations and Mitigation" title="Direct link to Limitations and Mitigation" translate="no">â€‹</a></h3>
<p>Understanding synthetic data limitations:</p>
<ul>
<li class=""><strong>Simulation artifacts</strong>: Elements that don&#x27;t exist in reality</li>
<li class=""><strong>Missing physics</strong>: Real-world effects not modeled in simulation</li>
<li class=""><strong>Domain gap</strong>: Differences between synthetic and real data</li>
<li class=""><strong>Mitigation strategies</strong>: Domain randomization and validation</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="practical-implementation">Practical Implementation<a href="#practical-implementation" class="hash-link" aria-label="Direct link to Practical Implementation" title="Direct link to Practical Implementation" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="setting-up-synthetic-data-generation">Setting Up Synthetic Data Generation<a href="#setting-up-synthetic-data-generation" class="hash-link" aria-label="Direct link to Setting Up Synthetic Data Generation" title="Direct link to Setting Up Synthetic Data Generation" translate="no">â€‹</a></h3>
<p>Key considerations for effective synthetic data generation:</p>
<ul>
<li class=""><strong>Environment design</strong>: Creating diverse, realistic virtual worlds</li>
<li class=""><strong>Scenario planning</strong>: Designing systematic variations of parameters</li>
<li class=""><strong>Annotation pipeline</strong>: Ensuring consistent, high-quality ground truth</li>
<li class=""><strong>Quality control</strong>: Monitoring and validating generated data</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-pipeline-integration">Data Pipeline Integration<a href="#data-pipeline-integration" class="hash-link" aria-label="Direct link to Data Pipeline Integration" title="Direct link to Data Pipeline Integration" translate="no">â€‹</a></h3>
<p>Incorporating synthetic data into AI workflows:</p>
<ul>
<li class=""><strong>Data format compatibility</strong>: Ensuring synthetic data matches real data format</li>
<li class=""><strong>Training pipeline integration</strong>: Adding synthetic data to existing training workflows</li>
<li class=""><strong>Quality metrics</strong>: Monitoring synthetic data quality and effectiveness</li>
<li class=""><strong>Continuous generation</strong>: Setting up automated data generation pipelines</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="performance-optimization">Performance Optimization<a href="#performance-optimization" class="hash-link" aria-label="Direct link to Performance Optimization" title="Direct link to Performance Optimization" translate="no">â€‹</a></h3>
<p>Efficient synthetic data generation:</p>
<ul>
<li class=""><strong>Batch processing</strong>: Generating multiple samples in parallel</li>
<li class=""><strong>Hardware acceleration</strong>: Leveraging GPUs for rendering and processing</li>
<li class=""><strong>Scene optimization</strong>: Efficient scene design for fast rendering</li>
<li class=""><strong>Quality vs. speed trade-offs</strong>: Balancing data quality with generation speed</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="impact-on-humanoid-robotics">Impact on Humanoid Robotics<a href="#impact-on-humanoid-robotics" class="hash-link" aria-label="Direct link to Impact on Humanoid Robotics" title="Direct link to Impact on Humanoid Robotics" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="perception-system-development">Perception System Development<a href="#perception-system-development" class="hash-link" aria-label="Direct link to Perception System Development" title="Direct link to Perception System Development" translate="no">â€‹</a></h3>
<p>Synthetic data accelerates humanoid robot perception development:</p>
<ul>
<li class=""><strong>Diverse training</strong>: Robots can encounter many scenarios before deployment</li>
<li class=""><strong>Safe learning</strong>: Complex behaviors can be learned without physical risk</li>
<li class=""><strong>Cost reduction</strong>: Dramatically reduces data collection costs</li>
<li class=""><strong>Faster iteration</strong>: Rapid testing of different perception approaches</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="generalization-to-real-world">Generalization to Real World<a href="#generalization-to-real-world" class="hash-link" aria-label="Direct link to Generalization to Real World" title="Direct link to Generalization to Real World" translate="no">â€‹</a></h3>
<p>For humanoid robots operating in human environments:</p>
<ul>
<li class=""><strong>Environment diversity</strong>: Training on varied indoor and outdoor scenes</li>
<li class=""><strong>Human interaction</strong>: Learning to perceive and understand human behavior</li>
<li class=""><strong>Social scenarios</strong>: Understanding social contexts and norms</li>
<li class=""><strong>Robust perception</strong>: Reliable performance across different conditions</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="challenges-and-future-directions">Challenges and Future Directions<a href="#challenges-and-future-directions" class="hash-link" aria-label="Direct link to Challenges and Future Directions" title="Direct link to Challenges and Future Directions" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-reality-gap">The Reality Gap<a href="#the-reality-gap" class="hash-link" aria-label="Direct link to The Reality Gap" title="Direct link to The Reality Gap" translate="no">â€‹</a></h3>
<p>Ongoing challenges in synthetic-to-real transfer:</p>
<ul>
<li class=""><strong>Visual differences</strong>: Subtle differences between synthetic and real images</li>
<li class=""><strong>Physics approximations</strong>: Simulation physics may not perfectly match reality</li>
<li class=""><strong>Sensor modeling</strong>: Virtual sensors may not perfectly match real ones</li>
<li class=""><strong>Emerging solutions</strong>: Advanced domain adaptation techniques</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="computational-requirements">Computational Requirements<a href="#computational-requirements" class="hash-link" aria-label="Direct link to Computational Requirements" title="Direct link to Computational Requirements" translate="no">â€‹</a></h3>
<p>Synthetic data generation demands:</p>
<ul>
<li class=""><strong>High-performance hardware</strong>: GPUs for realistic rendering</li>
<li class=""><strong>Large storage requirements</strong>: Massive datasets require significant storage</li>
<li class=""><strong>Processing power</strong>: Real-time generation for interactive applications</li>
<li class=""><strong>Efficiency improvements</strong>: Ongoing research in efficient rendering</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">â€‹</a></h2>
<p>Synthetic data generation through Isaac Sim provides a revolutionary approach to training AI perception systems for humanoid robots. By creating photorealistic, perfectly annotated datasets at scale, synthetic data addresses the fundamental challenges of real-world data collection while enabling comprehensive training on diverse scenarios.</p>
<p>The combination of photorealistic rendering, perfect ground truth generation, and systematic variation through domain randomization makes synthetic data an invaluable tool for developing robust perception systems. When combined with real-world data and proper validation techniques, synthetic data enables the development of humanoid robots capable of reliable perception in complex, varied environments.</p>
<p>In the next section, we&#x27;ll explore Isaac ROS, the integration layer that connects NVIDIA&#x27;s hardware acceleration with ROS 2 for real-time perception and navigation.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/bydjusman/my-book/edit/main/docs/module-3-ai-robot-brain/synthetic-data.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/module-3-ai-robot-brain/isaac-ros"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Isaac ROS Integration</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/module-3-ai-robot-brain/vslam-navigation"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Visual SLAM &amp; Navigation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-challenge-of-real-world-data" class="table-of-contents__link toc-highlight">The Challenge of Real-World Data</a><ul><li><a href="#time-and-cost-constraints" class="table-of-contents__link toc-highlight">Time and Cost Constraints</a></li><li><a href="#limited-scenario-coverage" class="table-of-contents__link toc-highlight">Limited Scenario Coverage</a></li><li><a href="#quality-and-consistency-issues" class="table-of-contents__link toc-highlight">Quality and Consistency Issues</a></li></ul></li><li><a href="#what-is-synthetic-data" class="table-of-contents__link toc-highlight">What is Synthetic Data?</a></li><li><a href="#how-isaac-sim-generates-synthetic-data" class="table-of-contents__link toc-highlight">How Isaac Sim Generates Synthetic Data</a><ul><li><a href="#photorealistic-rendering-pipeline" class="table-of-contents__link toc-highlight">Photorealistic Rendering Pipeline</a></li><li><a href="#ground-truth-generation" class="table-of-contents__link toc-highlight">Ground Truth Generation</a></li><li><a href="#automated-annotation" class="table-of-contents__link toc-highlight">Automated Annotation</a></li></ul></li><li><a href="#benefits-of-synthetic-data-for-perception-training" class="table-of-contents__link toc-highlight">Benefits of Synthetic Data for Perception Training</a><ul><li><a href="#unlimited-data-generation" class="table-of-contents__link toc-highlight">Unlimited Data Generation</a></li><li><a href="#controlled-variation" class="table-of-contents__link toc-highlight">Controlled Variation</a></li><li><a href="#perfect-annotations" class="table-of-contents__link toc-highlight">Perfect Annotations</a></li><li><a href="#edge-case-generation" class="table-of-contents__link toc-highlight">Edge Case Generation</a></li></ul></li><li><a href="#use-cases-for-perception-training" class="table-of-contents__link toc-highlight">Use Cases for Perception Training</a><ul><li><a href="#object-detection-and-recognition" class="table-of-contents__link toc-highlight">Object Detection and Recognition</a></li><li><a href="#semantic-segmentation" class="table-of-contents__link toc-highlight">Semantic Segmentation</a></li><li><a href="#depth-estimation" class="table-of-contents__link toc-highlight">Depth Estimation</a></li><li><a href="#pose-estimation" class="table-of-contents__link toc-highlight">Pose Estimation</a></li></ul></li><li><a href="#domain-randomization" class="table-of-contents__link toc-highlight">Domain Randomization</a><ul><li><a href="#visual-domain-randomization" class="table-of-contents__link toc-highlight">Visual Domain Randomization</a></li><li><a href="#physical-domain-randomization" class="table-of-contents__link toc-highlight">Physical Domain Randomization</a></li><li><a href="#benefits-of-domain-randomization" class="table-of-contents__link toc-highlight">Benefits of Domain Randomization</a></li></ul></li><li><a href="#combining-synthetic-and-real-data" class="table-of-contents__link toc-highlight">Combining Synthetic and Real Data</a><ul><li><a href="#data-augmentation" class="table-of-contents__link toc-highlight">Data Augmentation</a></li><li><a href="#sim-to-real-transfer" class="table-of-contents__link toc-highlight">Sim-to-Real Transfer</a></li><li><a href="#hybrid-training-approaches" class="table-of-contents__link toc-highlight">Hybrid Training Approaches</a></li></ul></li><li><a href="#quality-considerations" class="table-of-contents__link toc-highlight">Quality Considerations</a><ul><li><a href="#simulation-fidelity" class="table-of-contents__link toc-highlight">Simulation Fidelity</a></li><li><a href="#validation-approaches" class="table-of-contents__link toc-highlight">Validation Approaches</a></li><li><a href="#limitations-and-mitigation" class="table-of-contents__link toc-highlight">Limitations and Mitigation</a></li></ul></li><li><a href="#practical-implementation" class="table-of-contents__link toc-highlight">Practical Implementation</a><ul><li><a href="#setting-up-synthetic-data-generation" class="table-of-contents__link toc-highlight">Setting Up Synthetic Data Generation</a></li><li><a href="#data-pipeline-integration" class="table-of-contents__link toc-highlight">Data Pipeline Integration</a></li><li><a href="#performance-optimization" class="table-of-contents__link toc-highlight">Performance Optimization</a></li></ul></li><li><a href="#impact-on-humanoid-robotics" class="table-of-contents__link toc-highlight">Impact on Humanoid Robotics</a><ul><li><a href="#perception-system-development" class="table-of-contents__link toc-highlight">Perception System Development</a></li><li><a href="#generalization-to-real-world" class="table-of-contents__link toc-highlight">Generalization to Real World</a></li></ul></li><li><a href="#challenges-and-future-directions" class="table-of-contents__link toc-highlight">Challenges and Future Directions</a><ul><li><a href="#the-reality-gap" class="table-of-contents__link toc-highlight">The Reality Gap</a></li><li><a href="#computational-requirements" class="table-of-contents__link toc-highlight">Computational Requirements</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li></ul></div></div></div></div></main></div></div><button class="chatbot-float-button" aria-label="Open chatbot"><span class="chatbot-icon">ðŸ¤–</span><span class="chatbot-text">Ask the Book</span></button></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Textbook</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Introduction</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 Physical AI & Humanoid Robotics Textbook. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>